{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARhK6VBUVvrX"
      },
      "source": [
        "# Colab Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euHXFvciJYjp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDMHlz470F47"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "print(\"GPU allocated:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5PnHMoyLPDK"
      },
      "source": [
        "# Preparing Local Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJv9qNHGKRhz"
      },
      "outputs": [],
      "source": [
        "# copy from drive to local /data/\n",
        "!mkdir /data\n",
        "!cp /content/drive/MyDrive/data/pokemon_images.zip /data\n",
        "!unzip -q -n /data/pokemon_images.zip -d /data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaPlgvG0TFil"
      },
      "outputs": [],
      "source": [
        "experiment_name = \"pokegen_type_reacgan_arange\"\n",
        "\n",
        "DATASET_ROOT = \"/data/pokemon_images\"\n",
        "CHECKPOINT_ROOT = f\"/content/drive/MyDrive/checkpoints/{experiment_name}\"\n",
        "TEST_RESULTS_ROOT = f\"/content/drive/MyDrive/test_results/{experiment_name}\"\n",
        "GEN_RESULTS_ROOT = f\"/content/drive/MyDrive/gen_results/{experiment_name}\"\n",
        "\n",
        "import os\n",
        "os.makedirs(DATASET_ROOT, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_ROOT, exist_ok=True)\n",
        "os.makedirs(TEST_RESULTS_ROOT, exist_ok=True)\n",
        "os.makedirs(GEN_RESULTS_ROOT, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH1aoSrELYTc"
      },
      "source": [
        "# Imports and helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kkBQQuCKXGy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import datetime\n",
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ioff()\n",
        "%matplotlib inline\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.parametrizations import spectral_norm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable, grad\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matplotlib_to_PIL(fig):\n",
        "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
        "    buffer = io.BytesIO()\n",
        "    fig.savefig(buffer, bbox_inches='tight')\n",
        "    buffer.seek(0)\n",
        "    image = Image.open(buffer)\n",
        "    return image"
      ],
      "metadata": {
        "id": "eXE4lbSKgw9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TK2M-f1L2xM"
      },
      "source": [
        "# Dataset Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whbMaL4jKXwD"
      },
      "outputs": [],
      "source": [
        "class PokemonSpritesDataset(Dataset):\n",
        "    \"\"\"Pokemon Sprites dataset for conditional GANs, with front/back, type and shape label.\"\"\"\n",
        "\n",
        "    exclude_pokedex_id = [707, 708, 709, 867, 868]  # manually exclude some Pokemon's images\n",
        "    \n",
        "    def __init__(self, root_dir, use_shiny=False, use_back=True, use_shape=True, \n",
        "                 use_types=True, type2_prob=0.7, orient_weight=10):\n",
        "        self.root_dir = root_dir\n",
        "        self.use_shiny = use_shiny\n",
        "        self.use_back = use_back\n",
        "        self.use_shape = use_shape\n",
        "        self.use_types = use_types\n",
        "        self.type2_prob = type2_prob\n",
        "        self.orient_weight = orient_weight\n",
        "\n",
        "        self.sprites_dir = os.path.join(self.root_dir, \"sprites\")\n",
        "        \n",
        "        ## Pokemon metadata (labels)\n",
        "        self.pokedex_df = pd.read_csv(os.path.join(root_dir, \"pokedex.csv\"))\n",
        "\n",
        "        # Respectively binarize shape and type labels\n",
        "        tmp_shape_labels = list(self.pokedex_df[\"shape\"].unique())\n",
        "        self.shape_binarizer = MultiLabelBinarizer().fit([tmp_shape_labels])\n",
        "        self.shape_labels = self.shape_binarizer.classes_.tolist()\n",
        "\n",
        "        tmp_type_labels = list(self.pokedex_df[\"type1\"].unique())\n",
        "        self.type_binarizer = MultiLabelBinarizer().fit([tmp_type_labels])\n",
        "        self.type_labels = self.type_binarizer.classes_.tolist()\n",
        "\n",
        "        self.orient_count_df = pd.DataFrame(np.zeros((1, 2), dtype=np.int32), \n",
        "                                         index=[\"Count\"], columns=[\"front\", \"back\"])\n",
        "        self.shapes_count_df = pd.DataFrame(np.zeros((1, len(self.shape_labels)), dtype=np.int32), \n",
        "                                         index=[\"Count\"], columns=self.shape_labels)\n",
        "        self.types_count_df = pd.DataFrame(np.zeros((1, len(self.type_labels)), dtype=np.int32), \n",
        "                                         index=[\"Count\"], columns=self.type_labels)\n",
        "\n",
        "        ## Preprocessing\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        \n",
        "        ## Read sprite images\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for entry in os.scandir(self.sprites_dir):\n",
        "            if not entry.is_dir():\n",
        "                continue\n",
        "\n",
        "            pokedex_id = int(entry.name[:4])\n",
        "\n",
        "            if pokedex_id in self.exclude_pokedex_id:\n",
        "                continue\n",
        "\n",
        "            shape = self.pokedex_df.iloc[pokedex_id][\"shape\"]\n",
        "            type1 = self.pokedex_df.iloc[pokedex_id][\"type1\"]\n",
        "            type2 = self.pokedex_df.iloc[pokedex_id][\"type2\"]\n",
        "\n",
        "            image_dirs = [\n",
        "                os.path.join(entry.path, \"front\", \"normal\")\n",
        "            ]\n",
        "            if self.use_back:\n",
        "                image_dirs.append(os.path.join(entry.path, \"back\", \"normal\"))\n",
        "            if self.use_shiny:\n",
        "                image_dirs.append(os.path.join(entry.path, \"front\", \"shiny\"))\n",
        "                if self.use_back:\n",
        "                    image_dirs.append(os.path.join(entry.path, \"back\", \"shiny\"))\n",
        "\n",
        "            for image_dir in image_dirs:\n",
        "                is_front = \"/front/\" in image_dir                \n",
        "                \n",
        "                for fn in os.listdir(image_dir):\n",
        "                    if not fn.endswith(\".png\"):\n",
        "                        continue\n",
        "\n",
        "                    image = Image.open(os.path.join(image_dir, fn))\n",
        "                    self.images.append(self.transform(image))\n",
        "\n",
        "                    labels_binarized = self.binarize_label(is_front, shape, (type1, type2))\n",
        "                    self.labels.append(labels_binarized)\n",
        "\n",
        "                    self.orient_count_df.iloc[0][\"front\" if is_front else \"back\"] += 1\n",
        "                    self.shapes_count_df.iloc[0][shape] += 1\n",
        "                    self.types_count_df.iloc[0][type1] += 1\n",
        "                    if type2 is not np.nan:\n",
        "                        self.types_count_df.iloc[0][type2] += 1\n",
        "        \n",
        "        self.images = torch.from_numpy(np.stack(self.images))\n",
        "        self.labels = torch.from_numpy(np.stack(self.labels))\n",
        "\n",
        "        self.n_labels = self.labels.shape[-1]\n",
        "        self.shape_labels_weights = np.asarray(\n",
        "            self.shapes_count_df.iloc[0].max() / self.shapes_count_df.iloc[0])\n",
        "        self.type_labels_weights = np.asarray(\n",
        "            self.types_count_df.iloc[0].max() / self.types_count_df.iloc[0])\n",
        "\n",
        "        self.labels_weights = []\n",
        "        if self.use_back:\n",
        "            self.labels_weights.append([self.orient_weight])\n",
        "        if self.use_shape:\n",
        "            self.labels_weights.append(self.shape_labels_weights)\n",
        "        if self.use_types:\n",
        "            self.labels_weights.append(self.type_labels_weights)\n",
        "        self.labels_weights = np.concatenate(self.labels_weights)\n",
        "\n",
        "        print(\"Images shape:\", self.images.shape)\n",
        "        print(\"Labels shape:\", self.labels.shape)\n",
        "        print(\"Labels weights:\", self.labels_weights)\n",
        "\n",
        "    def binarize_label(self, is_front, shape, types):\n",
        "        labels = []\n",
        "        \n",
        "        if self.use_back:\n",
        "            labels.append([1] if is_front else [0])\n",
        "\n",
        "        if self.use_shape:\n",
        "            labels.append(self.shape_binarizer.transform([[shape]])[0])\n",
        "\n",
        "        if self.use_types:\n",
        "            type_x = self.type_binarizer.transform([[types[0]]])[0].astype(float)  # type 1\n",
        "            if len(types) == 2 and types[1] is not np.nan:\n",
        "                type_x += self.type_binarizer.transform([[types[1]]])[0] * self.type2_prob\n",
        "            labels.append(type_x)\n",
        "\n",
        "        return np.concatenate(labels)\n",
        "\n",
        "    def target_binarized_label_mask(self, orient=False, shape=False, types=False):\n",
        "        \"\"\"Return the mask to extract the target part from the binarized label.\"\"\"\n",
        "        \n",
        "        assert(orient + shape + types == 1)  # only one of the orient, shape, types can be true\n",
        "\n",
        "        mask = torch.zeros(self.n_labels).bool()\n",
        "        if orient:\n",
        "            assert(self.use_back)\n",
        "            mask[0] = True\n",
        "        \n",
        "        if shape:\n",
        "            assert(self.use_shape)\n",
        "            start_idx = 1 if self.use_back else 0\n",
        "            mask[start_idx: start_idx + len(self.shape_labels)] = True\n",
        "        \n",
        "        if types:\n",
        "            assert(self.use_types)\n",
        "            start_idx = 0\n",
        "            if self.use_back:\n",
        "                start_idx += 1\n",
        "            if self.use_shape:\n",
        "                start_idx += len(self.shape_labels)\n",
        "            mask[start_idx: start_idx + len(self.type_labels)] = True\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def type_onehot_label_to_num_label(self, type_label, ignore_type2=True):\n",
        "        # label must have length len(self.type_labels)\n",
        "        type_num_labels = (type_label == 1).nonzero()[:, 1]  # only use the primary type\n",
        "        return type_num_labels\n",
        "\n",
        "    def inverse_binarize_label(self, labels):\n",
        "        # input labels: (N, n_labels)\n",
        "        all_labels_text = []\n",
        "\n",
        "        for i in range(labels.shape[0]):\n",
        "            labels_text = []\n",
        "\n",
        "            if self.use_back:\n",
        "                if labels[i][self.target_binarized_label_mask(orient=True)]:\n",
        "                    labels_text.append(\"front\")\n",
        "                else:\n",
        "                    labels_text.append(\"back\")\n",
        "            \n",
        "            if self.use_shape:\n",
        "                labels_text.append(self.shape_binarizer.inverse_transform(\n",
        "                    labels[i][self.target_binarized_label_mask(shape=True)][None, :].numpy())[0][0]\n",
        "                )\n",
        "            \n",
        "            if self.use_types:\n",
        "                types_x = labels[i][self.target_binarized_label_mask(types=True)].numpy()\n",
        "                type1_x = np.array(types_x == 1., dtype=float)\n",
        "                type_text = list(self.type_binarizer.inverse_transform(type1_x[None, :])[0])  # [type1]\n",
        "                if np.any(types_x == self.type2_prob):  # if has type 2\n",
        "                    type2_x = np.array(types_x == self.type2_prob, dtype=float)\n",
        "                    type_text += list(self.type_binarizer.inverse_transform(type2_x[None, :])[0])\n",
        "                labels_text.append(type_text)\n",
        "\n",
        "            all_labels_text.append(labels_text)\n",
        "\n",
        "        return all_labels_text\n",
        "\n",
        "    def gen_random_labels(self, batch_size, test=False):\n",
        "        random_labels = []\n",
        "        for i in range(batch_size):\n",
        "            # Sample labels uniformly\n",
        "            is_front = random.choice([True, False])\n",
        "            rand_shape = random.choice(self.shape_labels)\n",
        "            rand_types = (random.choice(self.type_labels), )   # only for single type\n",
        "                \n",
        "            random_labels.append(self.binarize_label(is_front, rand_shape, rand_types))\n",
        "\n",
        "        return torch.from_numpy(np.stack(random_labels))\n",
        "\n",
        "    def make_images_grid(self, images, labels, row=8, col=8):\n",
        "        # draw images grid with input tensor image batch\n",
        "        fig, axs = plt.subplots(row, col, figsize=(row * 4, col * 2))\n",
        "\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                idx = i * row + j\n",
        "                label_text = self.inverse_binarize_label(labels[idx].unsqueeze(0))[0]\n",
        "                axs[i][j].axis('off')\n",
        "                axs[i][j].imshow(np.transpose(images[idx] * 0.5 + 0.5, (1, 2, 0)))\n",
        "                axs[i][j].set_title(str(label_text)[1:-1], fontsize=12)\n",
        "\n",
        "        image = matplotlib_to_PIL(fig)\n",
        "        plt.close(fig)\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOKUrc8q1KG9"
      },
      "outputs": [],
      "source": [
        "dataset = PokemonSpritesDataset(DATASET_ROOT, use_shiny=False, use_back=True, use_shape=False, use_types=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dispaly example training batch and statistics\n",
        "dataloader_example = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "example_images, example_labels = next(iter(dataloader_example))\n",
        "display(dataset.make_images_grid(example_images, example_labels))\n",
        "\n",
        "print(\"Orientation counts:\")\n",
        "display(dataset.orient_count_df)\n",
        "print(\"Shape counts:\")\n",
        "display(dataset.shapes_count_df)\n",
        "print(\"Type counts:\")\n",
        "display(dataset.types_count_df)"
      ],
      "metadata": {
        "id": "7Ao1OpvMvq-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_color_dict = {\"Bug\": \"#abb842\", \"Dark\": \"#6c594a\", \"Dragon\": \"#693bef\", \"Electric\": \"#f2d254\", \n",
        "                   \"Fairy\": \"#e66388\", \"Fighting\": \"#b13d31\", \"Fire\": \"#e18644\", \n",
        "                   \"Flying\": \"#a491ea\", \"Ghost\": \"#6c5994\", \"Grass\": \"#8bc660\", \"Ground\": \"#dbc175\",\n",
        "                   \"Ice\": \"#a6d6d7\", \"Normal\": \"#a8a87d\", \"Poison\": \"#94469b\", \"Psychic\": \"#e66388\",\n",
        "                   \"Rock\": \"#b4a14b\", \"Steel\": \"#b8b8ce\", \"Water\": \"#708fe9\"}\n",
        "plt.figure(figsize=(8, 6))\n",
        "dataset.types_count_df.iloc[0].plot.bar(color=type_color_dict.values())\n",
        "plt.title(\"#Images per Type\", fontsize=14)\n",
        "plt.xlabel(\"Type\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)"
      ],
      "metadata": {
        "id": "Z6tV2Vocvy9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "dataset.shapes_count_df.iloc[0].plot.bar()\n",
        "plt.title(\"#Images per Shape\", fontsize=14)\n",
        "plt.xlabel(\"Shape\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)"
      ],
      "metadata": {
        "id": "6TQwEFTJaBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 6))\n",
        "plt.rcParams[\"font.size\"] = 16\n",
        "dataset.orient_count_df.iloc[0].plot.bar(color=[\"blue\", \"orange\"])\n",
        "plt.title(\"#Images per Orientation\", fontsize=14)\n",
        "plt.xlabel(\"Orientation\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)"
      ],
      "metadata": {
        "id": "xgjAqeO1x_xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_5ndYBr57A0"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdditiveGaussianNoise(nn.Module):\n",
        "    def __init__(self, std=0.1, linear_decay_step=200000):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.linear_decay = self.std / linear_decay_step\n",
        "\n",
        "    def std_decay_step(self):\n",
        "        self.std = max(0, self.std - self.linear_decay)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            return x + torch.empty_like(x).normal_(std=self.std)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "def decay_gauss_std(module):\n",
        "    for m in module.modules():\n",
        "        if isinstance(m, AdditiveGaussianNoise):\n",
        "            m.std_decay_step()"
      ],
      "metadata": {
        "id": "hfwy9NxBNZe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLclg89cWkA4"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: (N, dim_z, 1, 1), (N, n_labels)\n",
        "    Output: (N, 3, 96, 96)\n",
        "    \"\"\"\n",
        "    def __init__(self, dim_z, n_labels):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.dim_z = dim_z\n",
        "        self.n_labels = n_labels\n",
        "\n",
        "        self.latent_dim = dim_z + n_labels\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.LazyConvTranspose2d(1024, kernel_size=6, stride=1, padding=0),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.backbone = nn.Sequential(*[\n",
        "            self.upsample_block(512),\n",
        "            self.upsample_block(256),\n",
        "            self.upsample_block(128),\n",
        "        ])\n",
        "\n",
        "        self.gen = nn.Sequential(\n",
        "            nn.LazyConvTranspose2d(3, kernel_size=4, stride=2, padding=1), \n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def upsample_block(self, num_filters):\n",
        "        layers = [\n",
        "            nn.LazyConvTranspose2d(num_filters, kernel_size=4, stride=2, padding=1, bias=False), \n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.LazyConv2d(num_filters, kernel_size=3, stride=1, padding=1, bias=False), \n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.LazyConv2d(num_filters, kernel_size=3, stride=1, padding=1, bias=False), \n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        ]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        noise_with_labels = torch.concat((noise, labels[:, :, None, None]), dim=1)\n",
        "        init_feat_map = self.linear(noise_with_labels)\n",
        "        final_feat_map = self.backbone(init_feat_map)\n",
        "        image = self.gen(final_feat_map)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZQyzd2YzQZX"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Assumption: all aux-labels are multi-label classification problem.\n",
        "    Input: (N, 3, 96, 96)\n",
        "    Output: (adv label (N, 1), aux labels (N, n_labels)]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_labels, embed_dim=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.n_labels = n_labels\n",
        "\n",
        "        self.backbone = nn.Sequential(*[\n",
        "            self.downsample_block(3, 64),\n",
        "            self.downsample_block(64, 128),\n",
        "            self.downsample_block(128, 256),\n",
        "            self.downsample_block(256, 512)\n",
        "        ])\n",
        "\n",
        "        self.adv_clf = nn.Sequential(\n",
        "            AdditiveGaussianNoise(),\n",
        "            spectral_norm(nn.Conv2d(512, 1, kernel_size=6, stride=1, padding=0)),\n",
        "            nn.Sigmoid()  # binary label\n",
        "        )\n",
        "\n",
        "        self.aux_clf = nn.Sequential(\n",
        "            AdditiveGaussianNoise(),\n",
        "            spectral_norm(nn.Conv2d(512, self.n_labels, kernel_size=6, stride=1, padding=0)),\n",
        "            nn.Sigmoid()  # multi-label\n",
        "        )\n",
        "\n",
        "    def downsample_block(self, in_channels, out_channels):\n",
        "        layers = [\n",
        "            AdditiveGaussianNoise(),\n",
        "            spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        ]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, images):\n",
        "        feat_maps = self.backbone(images)\n",
        "\n",
        "        adv_label = self.adv_clf(feat_maps).squeeze().unsqueeze(1)  # (N, 1)\n",
        "        aux_labels = self.aux_clf(feat_maps).squeeze()  # (N, n_labels)\n",
        "        if self.n_labels == 1:\n",
        "            aux_labels = aux_labels.unsqueeze(1)\n",
        "\n",
        "        return adv_label, aux_labels, feat_maps.reshape(images.size(0), -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt from https://github.com/POSTECH-CVLab/PyTorch-StudioGAN/blob/master/src/utils/losses.py#L162\n",
        "class Data2DataCrossEntropyLoss(nn.Module):\n",
        "  \n",
        "    def __init__(self, num_classes, embed_dim=128, temperature=0.5, m_p=0.95):\n",
        "        super(Data2DataCrossEntropyLoss, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.temperature = temperature\n",
        "        self.m_p = m_p\n",
        "\n",
        "        self.cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
        "\n",
        "        self.project_head = nn.Sequential(\n",
        "            nn.Linear(512 * 6 * 6, self.embed_dim * 2),  # manually set to the dim of feature map\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        )\n",
        "        self.embedding = nn.Embedding(num_classes, 128)\n",
        "\n",
        "    def calculate_similarity_matrix(self, x, y):\n",
        "        v = self.cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
        "        return v\n",
        "\n",
        "    def make_index_matrix(self, labels):\n",
        "        labels = labels.detach().cpu().numpy()\n",
        "        num_samples = labels.shape[0]\n",
        "        mask_multi, target = np.ones([self.num_classes, num_samples]), 0.0\n",
        "\n",
        "        for c in range(self.num_classes):\n",
        "            c_indices = np.where(labels == c)\n",
        "            mask_multi[c, c_indices] = target\n",
        "        return torch.tensor(mask_multi).type(torch.long).to(device)\n",
        "\n",
        "    def remove_diag(self, M):\n",
        "        h, w = M.shape\n",
        "        assert h==w, \"h and w should be same\"\n",
        "        mask = np.ones((h, w)) - np.eye(h)\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = (mask).type(torch.bool)\n",
        "        return M[mask].view(h, -1)\n",
        "\n",
        "    def forward(self, feat_map, label):\n",
        "        embed = self.project_head(feat_map)\n",
        "        embed = F.normalize(embed, dim=1)\n",
        "\n",
        "        proxy = self.embedding(label)\n",
        "        proxy = F.normalize(proxy, dim=1)\n",
        "\n",
        "        # calculate similarities between sample embeddings\n",
        "        sim_matrix = self.calculate_similarity_matrix(embed, embed) + self.m_p - 1\n",
        "        # remove diagonal terms\n",
        "        sim_matrix = self.remove_diag(sim_matrix / self.temperature)\n",
        "        # for numerical stability\n",
        "        sim_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)  # when i=j, the similarity with itself\n",
        "        sim_matrix = F.relu(sim_matrix) - sim_max.detach()\n",
        "\n",
        "        # calculate similarities between sample embeddings and the corresponding proxies\n",
        "        smp2proxy = self.cosine_similarity(embed, proxy)\n",
        "        # make false negative removal\n",
        "        removal_fn = self.remove_diag(self.make_index_matrix(label)[label])\n",
        "        # apply the negative removal to the similarity matrix\n",
        "        improved_sim_matrix = removal_fn * torch.exp(sim_matrix).to(device)\n",
        "\n",
        "        # compute positive attraction term\n",
        "        pos_attr = F.relu((self.m_p - smp2proxy) / self.temperature)\n",
        "        # compute negative repulsion term\n",
        "        neg_repul = torch.log(torch.exp(-pos_attr) + improved_sim_matrix.sum(dim=1))\n",
        "        # compute data to data cross-entropy criterion\n",
        "        criterion = pos_attr + neg_repul\n",
        "\n",
        "        return criterion.mean()"
      ],
      "metadata": {
        "id": "a02GfJ1EXxBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2PhBhpZ6P3G"
      },
      "outputs": [],
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck_wM1FEWP2g"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-WPfBEuqhVg"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91PobLzChyv6"
      },
      "outputs": [],
      "source": [
        "def save_generated_batch_from_fix_noise(save_dir, generator, iters, input):\n",
        "    iters_k = iters // 1000\n",
        "\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        gen_images = generator(*input).detach().cpu()\n",
        "    image = dataset.make_images_grid(gen_images, fixed_aux_labels.detach().cpu())\n",
        "\n",
        "    img_path = os.path.join(save_dir, f\"{iters_k:05d}k.png\")\n",
        "    image.save(img_path)\n",
        "    print(\"Saved generated image grid to\", img_path)\n",
        "\n",
        "def save_model(save_dir, generator, discriminator, iters):\n",
        "    iters_k = iters // 1000\n",
        "    G_path = os.path.join(save_dir,  f\"{iters_k:05d}k-G.pth\")\n",
        "    D_path = os.path.join(save_dir,  f\"{iters_k:05d}k-D.pth\")\n",
        "\n",
        "    torch.save(generator.state_dict(), G_path)\n",
        "    torch.save(discriminator.state_dict(), D_path)\n",
        "\n",
        "    print(\"Saved generator to\", G_path, \"and discriminator to\", D_path)\n",
        "\n",
        "def load_model(save_dir, generator, discriminator, iters):\n",
        "    iters_k = iters // 1000\n",
        "    G_path = os.path.join(save_dir,  f\"{iters_k:05d}k-G.pth\")\n",
        "    D_path = os.path.join(save_dir,  f\"{iters_k:05d}k-D.pth\")\n",
        "\n",
        "    generator.load_state_dict(torch.load(G_path))\n",
        "    discriminator.load_state_dict(torch.load(D_path))\n",
        "    \n",
        "    print(\"Loaded generator from\", G_path, \"and discriminator from\", D_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP6ewansucSx"
      },
      "outputs": [],
      "source": [
        "def gen_adv_labels(batch_size, real, smooth_real=False, noisy=False):\n",
        "    # output: (N, 1)\n",
        "    label = 1. if real else 0.\n",
        "    labels = torch.full((batch_size, 1), label, dtype=torch.float)\n",
        "\n",
        "    if noisy:\n",
        "        # randomly flip real and fake labels with probability 0.05\n",
        "        filped_labels = 1 - labels\n",
        "        if_filp = torch.rand((batch_size, )) < 0.05\n",
        "        labels[if_filp] = filped_labels[if_filp]\n",
        "\n",
        "    if smooth_real and real:\n",
        "        labels[labels == 1] = 0.9\n",
        "\n",
        "    return labels\n",
        "\n",
        "def gen_random_z(dim_z, batch_size):\n",
        "    return torch.randn((batch_size, dim_z, 1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Differentiable Augmentation for Data-Efficient GAN Training\n",
        "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
        "# https://arxiv.org/pdf/2006.10738\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_brightness(x):\n",
        "    # x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.3)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    # x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 1.5) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    # x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.3) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2).contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, ratio=0.25):  # origin: 0.5\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],\n",
        "}\n"
      ],
      "metadata": {
        "id": "pTL0bzLqQ1aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVLdwj8JKtoE"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J07m5KRWdxk"
      },
      "outputs": [],
      "source": [
        "# global settings\n",
        "def seed_everything(seed=7777):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DA_policy = \"color,translation,cutout\"\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Augmented Training Images\")\n",
        "plt.imshow(np.transpose(torchvision.utils.make_grid(DiffAugment(example_images, policy=DA_policy), normalize=True), (1, 2, 0)))"
      ],
      "metadata": {
        "id": "kPniJsx6SP4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93DseQMYUuK4"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "n_epochs = 10000\n",
        "\n",
        "dim_z = 100\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "lr_D = 0.0002\n",
        "lr_G = 0.0002\n",
        "\n",
        "lambda_aux = 0.25\n",
        "lambda_clr = 0.03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EmY1g8fKrRe"
      },
      "outputs": [],
      "source": [
        "## Models\n",
        "generator = Generator(dim_z, dataset.n_labels).to(device)\n",
        "generator.apply(weights_init)\n",
        "\n",
        "discriminator = Discriminator(dataset.n_labels).to(device)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "## Dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "## Losses\n",
        "# real/fake binary classification\n",
        "adv_criterion = nn.BCELoss()\n",
        "\n",
        "# multi-label classification, with label weigths\n",
        "aux_criterion = nn.BCELoss(reduction=\"none\")  \n",
        "aux_weights = torch.tensor(dataset.labels_weights).to(device)\n",
        "\n",
        "# contrastive loss for types\n",
        "clr_criterion = Data2DataCrossEntropyLoss(num_classes=dataset.n_labels - 1).to(device)\n",
        "\n",
        "## Optimizers\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
        "optimizer_clr = optim.Adam(clr_criterion.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
        "\n",
        "## Fixed noise for testing\n",
        "fixed_noise = gen_random_z(dim_z, 64).to(device)\n",
        "fixed_aux_labels = dataset.gen_random_labels(64, test=True).float().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNttLEGVKw7Z"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALsKHclgqPLf"
      },
      "outputs": [],
      "source": [
        "# If start from scratch\n",
        "iters = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ame3iM8TuHo"
      },
      "outputs": [],
      "source": [
        "# If resume from saved checkpoint\n",
        "iters = 190000\n",
        "load_model(CHECKPOINT_ROOT, generator, discriminator, iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwR_kUygzf4y"
      },
      "outputs": [],
      "source": [
        "log = True\n",
        "if log:\n",
        "    get_ipython().system(\"rm -rf ./runs\")  # clean logs\n",
        "    writer = SummaryWriter()\n",
        "    %tensorboard --logdir ./runs  # default dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr6j5yU_7DKg"
      },
      "outputs": [],
      "source": [
        "for epoch in range(n_epochs):\n",
        "    for i, (real_images, aux_labels) in enumerate(dataloader):\n",
        "        \n",
        "        real_images = real_images.to(device)\n",
        "        aux_labels = aux_labels.float().to(device)\n",
        "        clr_aux_labels = dataset.type_onehot_label_to_num_label(\n",
        "            aux_labels[:, dataset.target_binarized_label_mask(types=True)]).to(device)\n",
        "        cur_batch_size = real_images.shape[0]\n",
        "\n",
        "        noise = gen_random_z(dim_z, cur_batch_size).to(device)\n",
        "        random_aux_labels = dataset.gen_random_labels(cur_batch_size, test=False).float().to(device)\n",
        "        clr_random_aux_labels = dataset.type_onehot_label_to_num_label(\n",
        "            random_aux_labels[:, dataset.target_binarized_label_mask(types=True)]).to(device)\n",
        "\n",
        "        discriminator.train()\n",
        "        generator.train()\n",
        "\n",
        "        ## Train D\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        # Real batch\n",
        "        adv_pred_D_real, aux_pred_D_real, featmap_D_real = discriminator(\n",
        "            DiffAugment(real_images, policy=DA_policy))\n",
        "        adv_labels_D_real = gen_adv_labels(cur_batch_size, real=True, \n",
        "                                           smooth_real=True, noisy=False).to(device)\n",
        "        \n",
        "        adv_loss_D_real = adv_criterion(adv_pred_D_real, adv_labels_D_real)\n",
        "        aux_loss_D_real = torch.mean(aux_weights * aux_criterion(aux_pred_D_real, aux_labels))\n",
        "        clr_loss_D_real = clr_criterion(featmap_D_real, clr_aux_labels)\n",
        "\n",
        "        # Fake batch\n",
        "        fake_images = generator(noise, random_aux_labels)\n",
        "        adv_pred_D_fake, aux_pred_D_fake, featmap_D_fake = discriminator(\n",
        "            DiffAugment(fake_images.detach(), policy=DA_policy))\n",
        "        adv_labels_D_fake = gen_adv_labels(cur_batch_size, real=False, noisy=False).to(device)\n",
        "        \n",
        "        adv_loss_D_fake = adv_criterion(adv_pred_D_fake, adv_labels_D_fake)\n",
        "        aux_loss_D_fake = torch.mean(aux_weights * aux_criterion(aux_pred_D_fake, random_aux_labels))\n",
        "        clr_loss_D_fake = clr_criterion(featmap_D_fake, clr_random_aux_labels)\n",
        "\n",
        "        # Update D\n",
        "        adv_loss_D = adv_loss_D_real + adv_loss_D_fake\n",
        "        aux_loss_D = aux_loss_D_real + aux_loss_D_fake\n",
        "        clr_loss_D = clr_loss_D_real + clr_loss_D_fake\n",
        "        loss_D =  adv_loss_D + lambda_aux * aux_loss_D + lambda_clr * clr_loss_D\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "        optimizer_clr.step()\n",
        "\n",
        "        ## Train G\n",
        "        generator.zero_grad()\n",
        "\n",
        "        # Fake labels are real for generator cost\n",
        "        adv_labels_G = gen_adv_labels(cur_batch_size, real=True,\n",
        "                                      smooth_real=False, noisy=False).to(device)\n",
        "        adv_pred_G, aux_pred_G, featmap_G = discriminator(DiffAugment(fake_images, policy=DA_policy))\n",
        "\n",
        "        adv_loss_G = adv_criterion(adv_pred_G, adv_labels_G)\n",
        "        aux_loss_G = torch.mean(aux_weights * aux_criterion(aux_pred_G, random_aux_labels))\n",
        "        clr_loss_G = clr_criterion(featmap_G, clr_random_aux_labels)\n",
        "\n",
        "        # Update G\n",
        "        loss_G = adv_loss_G + lambda_aux * aux_loss_G + lambda_clr * clr_loss_G\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        ## At the end of each iteration\n",
        "        iters += 1\n",
        "        decay_gauss_std(discriminator)\n",
        "\n",
        "        # Print training statistics\n",
        "        D_x = adv_pred_D_real.mean().item()\n",
        "        D_G_z1 = adv_pred_D_fake.mean().item()\n",
        "        D_G_z2 = adv_pred_G.mean().item()\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "            print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
        "                  f\"Epoch [{epoch}/{n_epochs}] Batch [{i:02d}/{len(dataloader)}]:\",\n",
        "                  f\"Loss_D adv/aux/clr: {adv_loss_D.item():.4f} / {aux_loss_D.item():.4f} / {clr_loss_D.item():.4f},\",\n",
        "                  f\"Loss_G adv/aux/clr: {adv_loss_G.item():.4f} / {aux_loss_G.item():.4f} / {clr_loss_G.item():.4f}\",\n",
        "                  f\"D(x): {D_x:.4f}, D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}\")\n",
        "            if log:\n",
        "                writer.add_scalar(\"D(x)\", D_x, iters)\n",
        "                writer.add_scalar(\"D(G(z))_2\", D_G_z2, iters)\n",
        "                writer.add_scalar(\"Loss_D_adv\", adv_loss_D.item(), iters)\n",
        "                writer.add_scalar(\"Loss_D_aux\", aux_loss_D.item(), iters)\n",
        "                writer.add_scalar(\"Loss_D_clr\", clr_loss_D.item(), iters)\n",
        "                writer.add_scalar(\"Loss_G_adv\", adv_loss_G.item(), iters)\n",
        "                writer.add_scalar(\"Loss_G_aux\", aux_loss_G.item(), iters)\n",
        "                writer.add_scalar(\"Loss_G_clr\", clr_loss_G.item(), iters)\n",
        "                writer.flush()\n",
        "\n",
        "        # Saving G's output on fixed_noise and model weights\n",
        "        if (iters % 1000 == 0) or ((epoch == n_epochs - 1) and (i == len(dataloader) - 1)):\n",
        "            print(\"Saving generated images and model weights at iteration\", iters)\n",
        "            save_model(CHECKPOINT_ROOT, generator, discriminator, iters)\n",
        "            save_generated_batch_from_fix_noise(TEST_RESULTS_ROOT, generator, iters, \n",
        "                                                (fixed_noise, fixed_aux_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "t5qSwsvpvFV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_pokemon_with_types(type1, type2=None):\n",
        "    test_noise = gen_random_z(dim_z, 64).to(device)\n",
        "    test_aux_labels = torch.zeros(64, 19).to(device)\n",
        "    test_aux_labels[:, 0] = 1.  # front\n",
        "\n",
        "    test_aux_labels[:, 1 + dataset.type_labels.index(type1)] = 1.\n",
        "    if type2 is not None:\n",
        "        test_aux_labels[:, 1 + dataset.type_labels.index(type2)] = 0.7\n",
        "\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        gen_images = generator(test_noise, test_aux_labels).detach().cpu()\n",
        "\n",
        "    title = type1 + (\"\" if type2 is None else f\"+{type2}\")\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    \n",
        "    image_grid = torchvision.utils.make_grid(gen_images, normalize=True)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0))\n",
        "    plt.title(\"Generated Images of type \" + title, fontsize=14)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    image = matplotlib_to_PIL(fig)\n",
        "    plt.close(fig)\n",
        "    img_path = os.path.join(GEN_RESULTS_ROOT, f\"{iters // 1000:05d}k-{title}.png\")\n",
        "    image.save(img_path)"
      ],
      "metadata": {
        "id": "hhbE5XZnxdT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataset.type_labels)):\n",
        "    type_1 = dataset.type_labels[i]\n",
        "    print(f\"Generating {type_1}\")\n",
        "    gen_pokemon_with_types(type_1)\n",
        "    for j in range(len(dataset.type_labels)):\n",
        "        if i == j:\n",
        "            continue\n",
        "        type_2 = dataset.type_labels[j]\n",
        "        print(f\"Generating {type_1}+{type_2}\")\n",
        "        gen_pokemon_with_types(type_1, type_2)"
      ],
      "metadata": {
        "id": "esqxvLyB6nK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v5PnHMoyLPDK",
        "LH1aoSrELYTc",
        "3TK2M-f1L2xM",
        "Q_5ndYBr57A0",
        "d-WPfBEuqhVg",
        "lVLdwj8JKtoE"
      ],
      "name": "PokeTypeGAN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "background_execution": "on"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}